# Set everything to be logged to the console
#Global logging
log4j.rootCategory=WARN, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy-MM-dd HH:mm:ss} %p %c{1}: %m%n

# Spark 3.x
log4j.logger.org.sparkproject.jetty.server.handler.ContextHandler=WARN

# Spark 2.x
log4j.logger.org.spark_project.jetty.server.handler.ContextHandler=WARN

# Send WARN or higher to stderr
log4j.appender.stderr=org.apache.log4j.ConsoleAppender
log4j.appender.stderr.Threshold=WARN
log4j.appender.stderr.Target=System.err
log4j.appender.stderr.layout=org.apache.log4j.PatternLayout
log4j.appender.stderr.layout.ConversionPattern=%d{yy-MM-dd HH:mm:ss} %p %c{1}: %m%n

# Parquet related logging
log4j.logger.parquet.name = org.apache.parquet.CorruptStatistics
log4j.logger.parquet.level = WARN
log4j.logger.parquet2.name = parquet.CorruptStatistics
log4j.logger.parquet2.level = WARN

# Hive metastore related logging
logger.metastore.name = org.apache.hadoop.hive.metastore.RetryingHMSHandler
logger.metastore.level = FATAL
logger.hive_functionregistry.name = org.apache.hadoop.hive.ql.exec.FunctionRegistry
logger.hive_functionregistry.level = ERROR

# Settings to quiet third party logs that are too verbose
log4j.logger.org.eclipse.jetty=WARN
log4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO

# Reduce verbosity for other spammy core classes.
log4j.logger.org.apache.spark=WARN
log4j.logger.org.apache.spark.util=ERROR
log4j.logger.org.apache.spark.network=WARN
log4j.logger.akka=WARN
log4j.logger.org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter=WARN
log4j.logger.org.apache.hadoop.conf.Configuration.deprecation=WARN

# Hello Fresh com.vitthalmirji logging into separate file
log4j.logger.com.vitthalmirji=INFO, vimAppender
log4j.additivity.com.vitthalmirji=false
log4j.appender.vimAppender=org.apache.log4j.FileAppender
log4j.appender.vimAppender.File=${spark.yarn.app.container.log.dir}/stdout
log4j.appender.vimAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.vimAppender.layout.ConversionPattern=%d{yy-MM-dd HH:mm:ss} %p %c{1}: %m%n

# Spark Bigquery logging into separate file
log4j.logger.com.google.cloud.spark.bigquery=INFO, sparkbigqueryAppender
log4j.additivity.com.google.cloud.spark.bigquery=false
log4j.appender.sparkbigqueryAppender=org.apache.log4j.FileAppender
log4j.appender.sparkbigqueryAppender.File=${spark.yarn.app.container.log.dir}/spark-big-query.log
log4j.appender.sparkbigqueryAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.sparkbigqueryAppender.layout.ConversionPattern=%d{yy-MM-dd HH:mm:ss} %p %c{1}: %m%n

# Bigquery logging into separate file
log4j.logger.com.google.cloud.bigquery=INFO, bigqueryAppender
log4j.additivity.com.google.cloud.bigquery=false
log4j.appender.bigqueryAppender=org.apache.log4j.FileAppender
log4j.appender.bigqueryAppender.File=${spark.yarn.app.container.log.dir}/big-query.log
log4j.appender.bigqueryAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.bigqueryAppender.layout.ConversionPattern=%d{yy-MM-dd HH:mm:ss} %p %c{1}: %m%n

# Hudi logging into separate file
log4j.logger.org.apache.hudi=INFO, hudiAppender
log4j.additivity.org.apache.hudi=false
log4j.appender.hudiAppender=org.apache.log4j.FileAppender
log4j.appender.hudiAppender.File=${spark.yarn.app.container.log.dir}/hudi.log
log4j.appender.hudiAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.hudiAppender.layout.ConversionPattern=%d{yy-MM-dd HH:mm:ss} %p %c{1}: %m%n

# Cosmos logging into separate file
log4j.logger.com.microsoft.azure.cosmosdb=INFO, cosmosdbAppender
log4j.additivity.com.microsoft.azure.cosmosdb=false
log4j.appender.cosmosdbAppender=org.apache.log4j.FileAppender
log4j.appender.cosmosdbAppender.File=${spark.yarn.app.container.log.dir}/cosmosdb.log
log4j.appender.cosmosdbAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.cosmosdbAppender.layout.ConversionPattern=%d{yy-MM-dd HH:mm:ss} %p %c{1}: %m%n

# GCS logging into separate file
log4j.logger.com.google.cloud.storage=INFO, gcsAppender
log4j.additivity.com.google.cloud.storage=false
log4j.appender.gcsAppender=org.apache.log4j.FileAppender
log4j.appender.gcsAppender.File=${spark.yarn.app.container.log.dir}/gcs.log
log4j.appender.gcsAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.gcsAppender.layout.ConversionPattern=%d{yy-MM-dd HH:mm:ss} %p %c{1}: %m%n
